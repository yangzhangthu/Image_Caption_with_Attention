{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import vgg\n",
    "import time\n",
    "import FlickrDataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = r'./data/img/Flicker8k_Dataset/'\n",
    "cap_path = r'./data/label/Flickr8k.lemma.token.txt'\n",
    "train_txt = r'./data/label/Flickr_8k.trainImages.txt'\n",
    "val_txt = r'./data/label/Flickr_8k.devImages.txt'\n",
    "test_txt = r'./data/label/Flickr_8k.testImages.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VggConv(nn.Module):\n",
    "            def __init__(self, model):\n",
    "                super(VggConv, self).__init__()\n",
    "                self.features = nn.Sequential(\n",
    "                    *list(model.features.children())[:-3]\n",
    "                )\n",
    "            def forward(self, x):\n",
    "                x = self.features(x)\n",
    "                return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytransform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Scale((224,224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                # (H x W x C) in the range [0, 255] to (C x H x W) in the range [0.0, 1.0].\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "flicker8k_val = FlickrDataLoader.Flicker8k(img_dir, cap_path, val_txt, transform=mytransform, train=True)\n",
    "model = vgg.vgg16_bn(True)\n",
    "model.eval()\n",
    "model_conv = VggConv(model).cuda()\n",
    "bsz = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(flicker8k_val, batch_size=bsz,\n",
    "                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = None\n",
    "# w2id = {}\n",
    "# count = 0\n",
    "caption = []\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs\n",
    "    inputs, capt = data\n",
    "    # wrap them in Variable\n",
    "    inputs = Variable(inputs, volatile=True).cuda()\n",
    "    \n",
    "    out_ = model_conv(inputs)\n",
    "\n",
    "    if feat is None:\n",
    "        feat = out_.view(bsz,512,-1).transpose(1,2)\n",
    "    else:\n",
    "        feat = torch.cat((feat, out_.view(out_.data.shape[0], 512, -1).transpose(1,2)), 0)\n",
    "    \n",
    "    for k in range(out_.data.shape[0]):\n",
    "        cap = []\n",
    "        for j in range(5):\n",
    "            tmp = capt[j][k].lower().split(' ')\n",
    "            a = []\n",
    "            for l in tmp:\n",
    "                a.append(w2id[l])\n",
    "            cap.append(a)\n",
    "        caption.append(cap)\n",
    "\n",
    "#     for j in range(5):\n",
    "#         for k in range(out_.data.shape[0]):\n",
    "            \n",
    "#             tmp = capt[j][k].lower().split(' ')\n",
    "#             for l in tmp:\n",
    "#                 if l not in w2id:\n",
    "#                     w2id[l] = count\n",
    "#                     count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2w = {}\n",
    "# for (w,idx) in w2id.iteritems():\n",
    "#     id2w[idx] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('dict.pkl','w') as f:\n",
    "#     pickle.dump((w2id, id2w), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('feat.pkl','w') as f:\n",
    "#     pickle.dump(feat.data.cpu().numpy(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('capt.pkl','w') as f:\n",
    "#     pickle.dump(caption, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
